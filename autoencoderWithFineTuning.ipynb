{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(index, batch_size,total,data,labels):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    start = index\n",
    "    end = index+batch_size if index+batch_size<= total else None\n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(title, images, n_col, n_row,image_shape = (28, 28)):\n",
    "    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
    "    plt.suptitle(title, size=16)\n",
    "    for i, comp in enumerate(images):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,            \n",
    "                   vmin=-vmax, vmax=vmax)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "# read training data from CSV file \n",
    "dataTrain = pd.read_csv('./kaggle-mnist/train.csv')\n",
    "images = dataTrain.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "labels_flat = dataTrain[[0]].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters Pre-training\n",
    "learning_rate_unsup = 0.01\n",
    "training_epochs_unsup = 10\n",
    "batch_size_unsup = 256\n",
    "display_step = 100\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 128 # 2nd layer num features\n",
    "n_input = images.shape[1] # MNIST data input (img shape: 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters Fine Tuning\n",
    "learning_rate_sup= 0.001\n",
    "training_epochs_sup = 10\n",
    "batch_size_sup = 100\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "y = tf.placeholder(\"float\", [None, labels_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "with tf.variable_scope(\"semitraining\"):\n",
    "    weights = {\n",
    "        'encoder_h1': tf.get_variable(initializer=tf.random_normal([n_input, n_hidden_1]),name=\"encoder_h1\"),\n",
    "        'encoder_h2': tf.get_variable(initializer=tf.random_normal([n_hidden_1, n_hidden_2]),name=\"encoder_h2\"),\n",
    "        'decoder_h1': tf.get_variable(initializer=tf.random_normal([n_hidden_2, n_hidden_1]),name=\"decoder_h1\"),\n",
    "        'decoder_h2': tf.get_variable(initializer=tf.random_normal([n_hidden_1, n_input]),name=\"decoder_h2\"),\n",
    "    }\n",
    "    biases = {\n",
    "        'encoder_b1': tf.get_variable(initializer=tf.random_normal([n_hidden_1]),name=\"encoder_b1\"),\n",
    "        'encoder_b2': tf.get_variable(initializer=tf.random_normal([n_hidden_2]),name=\"encoder_b2\"),\n",
    "        'decoder_b1': tf.get_variable(initializer=tf.random_normal([n_hidden_1]),name=\"decoder_b1\"),\n",
    "        'decoder_b2': tf.get_variable(initializer=tf.random_normal([n_input]),name=\"decoder_b2\"),\n",
    "    }\n",
    "    # tf Graph input (only pictures)\n",
    "    #finetuning\n",
    "    weights['out_h3'] = tf.get_variable(initializer=tf.random_normal([n_input, labels_count]),name=\"out_h3\")\n",
    "    biases['out_b3'] = tf.get_variable(initializer=tf.random_normal([labels_count]),name=\"out_b3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['decoder_h1']), biases['decoder_b1'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['decoder_h2']), biases['decoder_b2'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out_h3']) + biases['out_b3']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def softmaxLast_layer(x, weights, biases):\n",
    "    encoder_op = encoder(X)\n",
    "    decoder_op = decoder(encoder_op)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(decoder_op, weights['out_h3']) + biases['out_b3']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"semitraining\",reuse=True):\n",
    "    # Construct model\n",
    "    encoder_op = encoder(X)\n",
    "    decoder_op = decoder(encoder_op)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = decoder_op\n",
    "    # Targets (Labels) are the input data.\n",
    "    y_true = X\n",
    "\n",
    "    # Define loss and optimizer, minimize the squared error\n",
    "    cost_unsup = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "    optimizer_unsup = tf.train.RMSPropOptimizer(learning_rate_unsup).minimize(cost_unsup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fine tuning\n",
    "# Construct model\n",
    "with tf.variable_scope(\"semitraining\",reuse=True):\n",
    "    pred = multilayer_perceptron(X, weights, biases)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost_sup = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "    optimizer_sup = tf.train.AdamOptimizer(learning_rate=learning_rate_sup).minimize(cost_sup,var_list=[tf.trainable_variables()[8],tf.trainable_variables()[9]])\n",
    "    \n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = int(images.shape[0]/batch_size_unsup)\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u'semitraining/encoder_h1:0'),\n",
       " (1, u'semitraining/encoder_h2:0'),\n",
       " (2, u'semitraining/decoder_h1:0'),\n",
       " (3, u'semitraining/decoder_h2:0'),\n",
       " (4, u'semitraining/encoder_b1:0'),\n",
       " (5, u'semitraining/encoder_b2:0'),\n",
       " (6, u'semitraining/decoder_b1:0'),\n",
       " (7, u'semitraining/decoder_b2:0'),\n",
       " (8, u'semitraining/out_h3:0'),\n",
       " (9, u'semitraining/out_b3:0')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, v.name) for i,v  in enumerate(tf.trainable_variables())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read test data from CSV file \n",
    "datatest = pd.read_csv('./kaggle-mnist/test.csv')\n",
    "imagestest = datatest.iloc[:,:].values\n",
    "imagestest = imagestest.astype(np.float)\n",
    "imagestest = np.multiply(imagestest, 1.0 / 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagestest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.655081451\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f87838199d0>> ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.118167\n",
      "Epoch: 0001 cost= 0.254383057\n",
      "Optimization Finished!\n",
      "Accuracy: 0.103167\n",
      "Epoch: 0001 cost= 158268.333984375\n",
      "Optimization Finished!\n",
      "Accuracy: 0.770048\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "# Using InteractiveSession (more convenient while using Notebooks)\n",
    "#tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    #sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    with tf.variable_scope(\"semitraining\",reuse=True):\n",
    "        \n",
    "        total_batch = int(images.shape[0]/batch_size_unsup)\n",
    "        \n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(\"Accuracy:\", accuracy.eval({X: images, y: labels}))\n",
    "        \n",
    "#         print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n",
    "#         print(sum(sum(sess.run(tf.trainable_variables()[8]))))\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs_unsup):\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = next_batch(i*batch_size_unsup, batch_size_unsup,images.shape[0],images,labels)\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                _, c = sess.run([optimizer_unsup, cost_unsup], feed_dict={X: batch_xs})\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "#                 print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n",
    "#                 print(sum(sum(sess.run(tf.trainable_variables()[8]))))\n",
    "\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "                      \"cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "#         print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n",
    "#         print(sum(sum(sess.run(tf.trainable_variables()[8]))))\n",
    "        \n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(\"Accuracy:\", accuracy.eval({X: images, y: labels}))\n",
    "        \n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs_sup):\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(images.shape[0]/batch_size_sup)\n",
    "            # Loop over all batches\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = next_batch(i*batch_size_sup, batch_size_sup,images.shape[0],images,labels)\n",
    "                # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                _, c = sess.run([optimizer_sup, cost_sup], feed_dict={X: batch_x,y: batch_y})\n",
    "                # Compute average loss\n",
    "                avg_cost += c / total_batch\n",
    "            # Display logs per epoch step\n",
    "            if epoch % display_step == 0:\n",
    "#                 print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n",
    "#                 print(sum(sum(sess.run(tf.trainable_variables()[8]))))\n",
    "                print( \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                    \"{:.9f}\".format(avg_cost))\n",
    "        print(\"Optimization Finished!\")\n",
    "    #         print(sum(sum(sess.run(tf.trainable_variables()[0]))))\n",
    "    #         print(sum(sum(sess.run(tf.trainable_variables()[8]))))\n",
    "\n",
    "\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(\"Accuracy:\", accuracy.eval({X: images, y: labels}))\n",
    "        # for i,val in enumeratete(tf.argmax(pred,1).eval({X:imagestest})):\n",
    "        #     print(i,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-65c8dc0c0d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Applying encode and decode over test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m encode_decode = sess.run(\n\u001b[0;32m----> 3\u001b[0;31m     y_pred, feed_dict={X: imagestest[:examples_to_show]})\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# Applying encode and decode over test set\n",
    "encode_decode = sess.run(\n",
    "    y_pred, feed_dict={X: imagestest[:examples_to_show]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare original images with their reconstructions\n",
    "plot_gallery('Base test MNIST',imagestest[:examples_to_show],examples_to_show/2,2)\n",
    "plot_gallery('Base test Encoded_Decoded MNIST',encode_decode[:examples_to_show],examples_to_show/2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
